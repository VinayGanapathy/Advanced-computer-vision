{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "advanced_computer_vision_with_python",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y3UgoDE1CJl"
      },
      "outputs": [],
      "source": [
        "# This is the backup of the video lecture https://www.youtube.com/watch?v=01sAkU_NvOY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chapter - 1 - lesson 1- Hand tracking basics (or) minimum (backup)"
      ],
      "metadata": {
        "id": "k2APPV1z1PSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(-1)\n",
        "\n",
        "mpHands = mp.solutions.hands\n",
        "hands = mpHands.Hands()\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "pTime = 0\n",
        "cTime = 0\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    results = hands.process(imgRGB)\n",
        "    #print(results.multi_hand_landmarks)\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        for handLms in results.multi_hand_landmarks:\n",
        "            for id, lm in enumerate(handLms.landmark):\n",
        "                h, w, c = img.shape\n",
        "                cx, cy = int(lm.x*w), int(lm.y*h)\n",
        "                print(id, cx, cy)\n",
        "                if id == 0:\n",
        "                    cv2.circle(img, (cx,cy), 15,(255,0,255), cv2.FILLED)\n",
        "\n",
        "            mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)\n",
        "\n",
        "\n",
        "    cTime = time.time()\n",
        "    fps = 1/(cTime-pTime)\n",
        "    pTime = cTime\n",
        "\n",
        "    cv2.putText(img, str(int(fps)), (10,70), cv2.FONT_HERSHEY_PLAIN, 3, (255,0,255), 3)\n",
        "\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "p7l2x-BN1W9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chapter 1 - lesson 2 - Hand Tracking Module"
      ],
      "metadata": {
        "id": "GjMTK8XP1rGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "\n",
        "\n",
        "class handDetector():\n",
        "    def __init__(self, mode=False, maxHands = 2, model_complexity=1, detectionCon = 0.5, trackCon=0.5):\n",
        "        self.mode = mode\n",
        "        self.maxHands = maxHands\n",
        "        self.model_complexity = model_complexity\n",
        "        self.detectionCon = detectionCon\n",
        "        self.trackCon = trackCon\n",
        "\n",
        "        self.mpHands = mp.solutions.hands\n",
        "        self.hands = self.mpHands.Hands(self.mode, self.maxHands, self.model_complexity,\n",
        "                                        self.detectionCon, self.trackCon)\n",
        "        self.mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "\n",
        "    def findHands(self, img, draw=True):\n",
        "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        self.results = self.hands.process(imgRGB)\n",
        "        # print(results.multi_hand_landmarks)\n",
        "\n",
        "        if self.results.multi_hand_landmarks:\n",
        "            for handLms in self.results.multi_hand_landmarks:\n",
        "                if draw:\n",
        "                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def findPosition(self, img, handNo=0, draw=True):\n",
        "\n",
        "        lmlist = []\n",
        "        if self.results.multi_hand_landmarks:\n",
        "            myHand = self.results.multi_hand_landmarks[handNo]\n",
        "            for id, lm in enumerate(myHand.landmark):\n",
        "                h, w, c = img.shape\n",
        "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "                #print(id, cx, cy)\n",
        "                lmlist.append([id, cx, cy])\n",
        "                #print(lmlist)\n",
        "                if draw:\n",
        "                    cv2.circle(img, (cx, cy), 15, (255, 0, 255), cv2.FILLED)\n",
        "\n",
        "        return lmlist\n",
        "\n",
        "\n",
        "def main():\n",
        "    pTime = 0\n",
        "    cTime = 0\n",
        "    cap = cv2.VideoCapture(-1)\n",
        "    detector = handDetector()\n",
        "    while True:\n",
        "        success, img = cap.read()\n",
        "        img = detector.findHands(img)\n",
        "        lmlist = detector.findPosition(img)\n",
        "        if len(lmlist) != 0:\n",
        "            print(lmlist[4])\n",
        "\n",
        "        cTime = time.time()\n",
        "        fps = 1 / (cTime - pTime)\n",
        "        pTime = cTime\n",
        "\n",
        "        cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)\n",
        "\n",
        "        cv2.imshow(\"Image\", img)\n",
        "        cv2.waitKey(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "5vW9mAa82wgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chapter-1- Lesson -2 - My New Game Hand Tracking (This should perform same as the above Hand Tracking module)"
      ],
      "metadata": {
        "id": "0Ra12pJ4JSis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "import HandTrackingModule as htm\n",
        "\n",
        "pTime = 0\n",
        "cTime = 0\n",
        "cap = cv2.VideoCapture(-1)\n",
        "detector = htm.handDetector()\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    img = detector.findHands(img)\n",
        "    lmlist = detector.findPosition(img)\n",
        "    if len(lmlist) != 0:\n",
        "        print(lmlist[4])\n",
        "\n",
        "    cTime = time.time()\n",
        "    fps = 1 / (cTime - pTime)\n",
        "    pTime = cTime\n",
        "\n",
        "    cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)\n",
        "\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "m1nKhMLXLe9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chapter 2 - Lesson 1 - Pose Estimation - Basics or Minimum"
      ],
      "metadata": {
        "id": "BkdaCXz4LgMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The videos in the PoseVideos folder is downloaded from https://www.pexels.com/license/ (Pexels.com)"
      ],
      "metadata": {
        "id": "8XRittJqbNpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "mpPose = mp.solutions.pose\n",
        "pose = mpPose.Pose()\n",
        "cap = cv2.VideoCapture('PoseVideos/3.mp4')\n",
        "pTime = 0\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    results = pose.process(imgRGB)\n",
        "    #print(results.pose_landmarks)\n",
        "    if results.pose_landmarks:\n",
        "        mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
        "        for id, lm in enumerate(results.pose_landmarks.landmark):\n",
        "            h, w, c = img.shape\n",
        "            print(id, lm)\n",
        "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "            cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
        "    cTime = time.time()\n",
        "    fps = 1 / (cTime - pTime)\n",
        "    pTime = cTime\n",
        "    cv2.putText(img, str(int(fps)), (70, 50), cv2.FONT_HERSHEY_PLAIN, 3,\n",
        "                 (255, 0, 0), 3)\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "RErfCja3bp2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chapter - 2 - Lesson -2 -  Pose Estimation - Module"
      ],
      "metadata": {
        "id": "U57XurvpvFRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "import math\n",
        "class poseDetector():\n",
        "    def __init__(self, mode=False, model_complexity=1, smooth=True, esegmentation=False,\n",
        "                 ssegmentation=True, detectionCon=0.5, trackCon=0.5):\n",
        "        self.mode = mode\n",
        "        self.model_complexity = model_complexity\n",
        "        self.smooth = smooth\n",
        "        self.esegmentation = esegmentation\n",
        "        self.ssegmentation = ssegmentation\n",
        "        self.detectionCon = detectionCon\n",
        "        self.trackCon = trackCon\n",
        "        self.mpDraw = mp.solutions.drawing_utils\n",
        "        self.mpPose = mp.solutions.pose\n",
        "        self.pose = self.mpPose.Pose(self.mode, self.model_complexity, self.smooth, self.esegmentation,\n",
        "                                     self.ssegmentation, self.detectionCon, self.trackCon)\n",
        "    def findPose(self, img, draw=True):\n",
        "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        self.results = self.pose.process(imgRGB)\n",
        "        if self.results.pose_landmarks:\n",
        "            if draw:\n",
        "                self.mpDraw.draw_landmarks(img, self.results.pose_landmarks,\n",
        "                                           self.mpPose.POSE_CONNECTIONS)\n",
        "        return img\n",
        "\n",
        "    def findPosition(self, img, draw=True):\n",
        "        self.lmList = []\n",
        "        if self.results.pose_landmarks:\n",
        "            for id, lm in enumerate(self.results.pose_landmarks.landmark):\n",
        "                h, w, c = img.shape\n",
        "                # print(id, lm)\n",
        "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "                self.lmList.append([id, cx, cy])\n",
        "                if draw:\n",
        "                    cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
        "        return self.lmList\n",
        "    \n",
        "def main():\n",
        "    cap = cv2.VideoCapture('PoseVideos/3.mp4')\n",
        "    pTime = 0\n",
        "    detector = poseDetector()\n",
        "    while True:\n",
        "        success, img = cap.read()\n",
        "        img = detector.findPose(img)\n",
        "        lmList = detector.findPosition(img, draw=False)\n",
        "        if len(lmList) != 0:\n",
        "            print(lmList[14])\n",
        "            cv2.circle(img, (lmList[14][1], lmList[14][2]), 15, (0, 0, 255), cv2.FILLED)\n",
        "        cTime = time.time()\n",
        "        fps = 1 / (cTime - pTime)\n",
        "        pTime = cTime\n",
        "        cv2.putText(img, str(int(fps)), (70, 50), cv2.FONT_HERSHEY_PLAIN, 3,\n",
        "                    (255, 0, 0), 3)\n",
        "        cv2.imshow(\"Image\", img)\n",
        "        cv2.waitKey(1)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "VQ6z5dGZ4RH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chapter - 2 - Lesson -3 -  OurAwesomePoseProject"
      ],
      "metadata": {
        "id": "zt6XsyP74VcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import PoseModule as pm\n",
        "\n",
        "cap = cv2.VideoCapture('PoseVideos/3.mp4')\n",
        "pTime = 0\n",
        "detector = pm.poseDetector()\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    img = detector.findPose(img)\n",
        "    lmList = detector.findPosition(img, draw=False)\n",
        "    if len(lmList) !=0:\n",
        "        print(lmList[14])\n",
        "        cv2.circle(img, (lmList[14][1], lmList[14][2]), 15, (0, 0, 255), cv2.FILLED)\n",
        "    cTime = time.time()\n",
        "    fps = 1 / (cTime - pTime)\n",
        "    pTime = cTime\n",
        "    cv2.putText(img, str(int(fps)), (70, 50), cv2.FONT_HERSHEY_PLAIN, 3,\n",
        "                (255, 0, 0), 3)\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "auIpK-KL4eqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chapter - 3 - Lesson -1 -  Face Detection Basics or minimum"
      ],
      "metadata": {
        "id": "FBrxXonr7AEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "\n",
        "cap = cv2.VideoCapture(\"Videos/4.mp4\")\n",
        "pTime = 0\n",
        "\n",
        "mpFaceDetection = mp.solutions.face_detection\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "faceDetection = mpFaceDetection.FaceDetection(0.75)\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "\n",
        "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    results = faceDetection.process(imgRGB)\n",
        "    # print(results)\n",
        "\n",
        "    if results.detections:\n",
        "        for id, detection in enumerate(results.detections):\n",
        "            # mpDraw.draw_detection(img, detection)\n",
        "            # print(id, detection)\n",
        "            # print(detection.score)\n",
        "            # print(detection.location_data.relative_bounding_box)\n",
        "            bboxC = detection.location_data.relative_bounding_box\n",
        "            ih, iw, ic = img.shape\n",
        "            bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
        "                   int(bboxC.width * iw), int(bboxC.height * ih)\n",
        "            cv2.rectangle(img, bbox, (255, 0, 255), 2)\n",
        "            cv2.putText(img, f'{int(detection.score[0] * 100)}%',\n",
        "                       (bbox[0], bbox[1] - 20), cv2.FONT_HERSHEY_PLAIN,\n",
        "                       2, (255, 0, 255), 2)\n",
        "\n",
        "    cTime = time.time()\n",
        "    fps = 1 / (cTime - pTime)\n",
        "    pTime = cTime\n",
        "    cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN,\n",
        "                3, (0, 255, 0), 2)\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "KRtbyrEC7M7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chapter - 3 - Lesson -2 -  Face Detection Module"
      ],
      "metadata": {
        "id": "z0i8FoVQFrPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "\n",
        "class FaceDetector():\n",
        "    def __init__(self, minDetectionCon=0.5, model_selection=0):\n",
        "        self.minDetectionCon = minDetectionCon\n",
        "        self.model_selection = model_selection\n",
        "        self.mpFaceDetection = mp.solutions.face_detection\n",
        "        self.mpDraw = mp.solutions.drawing_utils\n",
        "        self.faceDetection = self.mpFaceDetection.FaceDetection(self.minDetectionCon, self.model_selection)\n",
        "\n",
        "    def findFaces(self, img, draw=True):\n",
        "            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            self.results = self.faceDetection.process(imgRGB)\n",
        "            #print(self.results)\n",
        "            bboxs = []\n",
        "\n",
        "            if self.results.detections:\n",
        "                for id, detection in enumerate(self.results.detections):\n",
        "                    bboxC = detection.location_data.relative_bounding_box\n",
        "                    ih, iw, ic = img.shape\n",
        "                    bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih),\\\n",
        "                           int(bboxC.width * iw), int(bboxC.height * ih)\n",
        "                    bboxs.append([id, bbox, detection.score])\n",
        "                    if draw:\n",
        "                        img = self.fancyDraw(img,bbox)\n",
        "                        cv2.putText(img, f'{int(detection.score[0] * 100)}%',\n",
        "                                    (bbox[0], bbox[1] - 20), cv2.FONT_HERSHEY_PLAIN,\n",
        "                                    2, (255, 0, 255), 2)\n",
        "            return img, bboxs\n",
        "\n",
        "    def fancyDraw(self, img, bbox, l=30, t=5, rt= 1):\n",
        "        x, y, w, h = bbox\n",
        "        x1, y1 = x + w, y + h\n",
        "\n",
        "        cv2.rectangle(img, bbox, (255, 0, 255), rt)\n",
        "\n",
        "        # Top Left  x,y\n",
        "        cv2.line(img, (x, y), (x + l, y), (255, 0, 255), t)\n",
        "        cv2.line(img, (x, y), (x, y+l), (255, 0, 255), t)\n",
        "\n",
        "        # Top Right  x1,y\n",
        "        cv2.line(img, (x1, y), (x1 - l, y), (255, 0, 255), t)\n",
        "        cv2.line(img, (x1, y), (x1, y+l), (255, 0, 255), t)\n",
        "\n",
        "        # Bottom Left  x,y1\n",
        "        cv2.line(img, (x, y1), (x + l, y1), (255, 0, 255), t)\n",
        "        cv2.line(img, (x, y1), (x, y1 - l), (255, 0, 255), t)\n",
        "\n",
        "        # Bottom Right  x1,y1\n",
        "        cv2.line(img, (x1, y1), (x1 - l, y1), (255, 0, 255), t)\n",
        "        cv2.line(img, (x1, y1), (x1, y1 - l), (255, 0, 255), t)\n",
        "\n",
        "        return img\n",
        "\n",
        "def main():\n",
        "    cap = cv2.VideoCapture(\"Videos/4.mp4\")\n",
        "    pTime = 0\n",
        "    detector = FaceDetector()\n",
        "    while True:\n",
        "        success, img = cap.read()\n",
        "        img, bboxs = detector.findFaces(img)\n",
        "        #print(bboxs)\n",
        "        cTime = time.time()\n",
        "        fps = 1 / (cTime - pTime)\n",
        "        pTime = cTime\n",
        "        cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0), 2)\n",
        "        cv2.imshow(\"Image\", img)\n",
        "        cv2.waitKey(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "cvf8-icUFwgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chapter - 4 - Lesson -1 -  Face Mesh Basics or minimum"
      ],
      "metadata": {
        "id": "s5OGSgCAPWbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "\n",
        "cap = cv2.VideoCapture(\"Videos/7.mp4\")\n",
        "pTime = 0\n",
        "\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "mpFaceMesh = mp.solutions.face_mesh\n",
        "faceMesh = mpFaceMesh.FaceMesh(max_num_faces=2)\n",
        "drawSpec = mpDraw.DrawingSpec(thickness=1, circle_radius=2)\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    results = faceMesh.process(imgRGB)\n",
        "    if results.multi_face_landmarks:\n",
        "        for faceLms in results.multi_face_landmarks:\n",
        "            mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACEMESH_CONTOURS,\n",
        "                                  drawSpec,drawSpec)\n",
        "        for id, lm in enumerate(faceLms.landmark):\n",
        "            #print(lm)\n",
        "            ih, iw, ic = img.shape\n",
        "            x, y = int(lm.x * iw), int(lm.y * ih)\n",
        "            print(id, x, y)\n",
        "\n",
        "    cTime = time.time()\n",
        "    fps = 1 / (cTime - pTime)\n",
        "    pTime = cTime\n",
        "    cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN,\n",
        "                3, (255, 0, 0), 3)\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "EHCVqlcmPcix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chapter - 4 - Lesson -2 -  Face Mesh Module"
      ],
      "metadata": {
        "id": "UyMykwchOecq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "\n",
        "class FaceMeshDetector():\n",
        "    def __init__(self, staticMode=False, maxFaces=2, refine_landmarks=False, minDetectionCon=0.5, minTrackCon=0.5):\n",
        "        self.staticMode = staticMode\n",
        "        self.maxFaces = maxFaces\n",
        "        self.refine_landmarks = refine_landmarks\n",
        "        self.minDetectionCon = minDetectionCon\n",
        "        self.minTrackCon = minTrackCon\n",
        "\n",
        "        self.mpDraw = mp.solutions.drawing_utils\n",
        "        self.mpFaceMesh = mp.solutions.face_mesh\n",
        "        self.faceMesh = self.mpFaceMesh.FaceMesh(self.staticMode, self.maxFaces,self.refine_landmarks,\n",
        "                                                 self.minDetectionCon, self.minTrackCon)\n",
        "        self.drawSpec = self.mpDraw.DrawingSpec(thickness=1, circle_radius=2)\n",
        "\n",
        "    def findFaceMesh(self, img, draw=True):\n",
        "        self.imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        self.results = self.faceMesh.process(self.imgRGB)\n",
        "        faces = []\n",
        "        if self.results.multi_face_landmarks:\n",
        "            for faceLms in self.results.multi_face_landmarks:\n",
        "                if draw:\n",
        "                    self.mpDraw.draw_landmarks(img, faceLms, self.mpFaceMesh.FACEMESH_CONTOURS,\n",
        "                                               self.drawSpec, self.drawSpec)\n",
        "                face = []\n",
        "                for id,lm in enumerate(faceLms.landmark):\n",
        "                    #print(lm)\n",
        "                    ih, iw, ic = img.shape\n",
        "                    x,y = int(lm.x*iw), int(lm.y*ih)\n",
        "                    cv2.putText(img, str(id), (x, y), cv2.FONT_HERSHEY_PLAIN,0.7, (0, 255, 0), 1)\n",
        "                    #print(id,x,y)\n",
        "                    face.append([x,y])\n",
        "                faces.append(face)\n",
        "        return img, faces\n",
        "\n",
        "def main():\n",
        "    cap = cv2.VideoCapture(\"Videos/6.mp4\")\n",
        "    pTime = 0\n",
        "    detector = FaceMeshDetector(maxFaces=2)\n",
        "    while True:\n",
        "        success, img = cap.read()\n",
        "        img, faces = detector.findFaceMesh(img)\n",
        "        if len(faces)!= 0:\n",
        "            print(faces[0])\n",
        "        cTime = time.time()\n",
        "        fps = 1 / (cTime - pTime)\n",
        "        pTime = cTime\n",
        "        cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN,3, (0, 255, 0), 3)\n",
        "        cv2.imshow(\"Image\", img)\n",
        "        cv2.waitKey(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "LOoXCpKaOhbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Project - 1 - Volume Hand Control"
      ],
      "metadata": {
        "id": "rl4odxX-WUbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pycaw doesn't run on linux couldn't find a fix for it"
      ],
      "metadata": {
        "id": "Z9eyxmrBX6U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import HandTrackingModule as htm\n",
        "import math\n",
        "\n",
        "from ctypes import cast, POINTER\n",
        "from comtypes import CLSCTX_ALL\n",
        "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
        "\n",
        "\n",
        "# ################################\n",
        "wCam, hCam = 640, 480\n",
        "# ################################\n",
        "\n",
        "cap = cv2.VideoCapture(-1)\n",
        "cap.set(3, wCam)\n",
        "cap.set(4, hCam)\n",
        "pTime = 0\n",
        "detector = htm.handDetector(detectionCon=0.7)\n",
        "\n",
        "devices = AudioUtilities.GetSpeakers()\n",
        "interface = devices.Activate(\n",
        "    IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
        "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
        "# volume.GetMute()\n",
        "# volume.GetMasterVolumeLevel()\n",
        "volRange = volume.GetVolumeRange()\n",
        "#print(volRange)\n",
        "\n",
        "minVol = volRange[0]\n",
        "maxVol = volRange[1]\n",
        "vol = 0\n",
        "volBar = 400\n",
        "volPer = 0\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    img = detector.findHands(img)\n",
        "    lmList = detector.findPosition(img, draw=False)\n",
        "    if len(lmList) != 0:\n",
        "        #print(lmList[4], lmList[8])\n",
        "        x1, y1 = lmList[4][1], lmList[4][2]\n",
        "        x2, y2 = lmList[8][1], lmList[8][2]\n",
        "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "        cv2.circle(img, (x1, y1), 15, (255, 0, 255), cv2.FILLED)\n",
        "        cv2.circle(img, (x2, y2), 15, (255, 0, 255), cv2.FILLED)\n",
        "        cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
        "        cv2.circle(img, (cx, cy), 15, (255, 0, 255), cv2.FILLED)\n",
        "        length = math.hypot(x2 - x1, y2 - y1)\n",
        "        #print(length)\n",
        "\n",
        "       # Hand range 50 - 300\n",
        "        # Volume Range -65 - 0\n",
        "        vol = np.interp(length, [50, 300], [minVol, maxVol])\n",
        "        volBar = np.interp(length, [50, 300], [400, 150])\n",
        "        volPer = np.interp(length, [50, 300], [0, 100])\n",
        "        #print(int(length), vol)\n",
        "        volume.SetMasterVolumeLevel(vol, None)\n",
        "\n",
        "        if length<50:\n",
        "            cv2.circle(img, (cx, cy), 15, (0, 255, 0), cv2.FILLED)\n",
        "\n",
        "    cv2.rectangle(img, (50, 150), (85, 400), (255, 0, 0), 3)\n",
        "    cv2.rectangle(img, (50, int(volBar)), (85, 400), (255, 0, 0), cv2.FILLED)\n",
        "    cv2.putText(img, f'{int(volPer)} %', (40, 450), cv2.FONT_HERSHEY_COMPLEX,\n",
        "                1, (255, 0, 0), 3)\n",
        "\n",
        "    cTime = time.time()\n",
        "    fps = 1 / (cTime - pTime)\n",
        "    pTime = cTime\n",
        "    cv2.putText(img, f'FPS: {int(fps)}', (40, 50), cv2.FONT_HERSHEY_COMPLEX,\n",
        "                1, (255, 0, 0), 3)\n",
        "    cv2.imshow(\"Img\", img)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "qUQxeSTvihOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Project - 2 - Finger Counter"
      ],
      "metadata": {
        "id": "pAt1qP2cmF9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import os\n",
        "import HandTrackingModule as htm\n",
        "\n",
        "wCam, hCam = 640, 480\n",
        "cap = cv2.VideoCapture(-1)\n",
        "cap.set(3, wCam)\n",
        "cap.set(4, hCam)\n",
        "\n",
        "folderPath = \"FingerImages\"\n",
        "myList = os.listdir(folderPath)\n",
        "myList = sorted(myList)\n",
        "#print(myList)\n",
        "overlayList = []\n",
        "for imPath in myList:\n",
        "    image = cv2.imread(f'{folderPath}/{imPath}')\n",
        "    print(f'{folderPath}/{imPath}')\n",
        "    overlayList.append(image)\n",
        "#print(overlayList)\n",
        "\n",
        "pTime = 0\n",
        "\n",
        "detector = htm.handDetector(detectionCon=0.75)\n",
        "tipIds = [4, 8, 12, 16, 20]\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    img = detector.findHands(img)\n",
        "    lmList = detector.findPosition(img, draw=False)\n",
        "    #print(lmList)\n",
        "    if len(lmList) != 0:\n",
        "        fingers = []\n",
        "        # Thumb\n",
        "        if lmList[tipIds[0]][1] > lmList[tipIds[0] - 1][1]:\n",
        "            fingers.append(1)\n",
        "        else:\n",
        "            fingers.append(0)\n",
        "\n",
        "        # 4 Fingers\n",
        "        for id in range(1, 5):\n",
        "            if lmList[tipIds[id]][2] < lmList[tipIds[id] - 2][2]:\n",
        "                fingers.append(1)\n",
        "            else:\n",
        "                fingers.append(0)\n",
        "        #print(fingers)\n",
        "        totalFingers = fingers.count(1)\n",
        "        #print(totalFingers-1)\n",
        "\n",
        "        h, w, c = overlayList[totalFingers - 1].shape\n",
        "        img[0:h, 0:w] = overlayList[totalFingers - 1]\n",
        "\n",
        "        cv2.rectangle(img, (20, 300), (170, 450), (0, 255, 0), cv2.FILLED)\n",
        "        cv2.putText(img, str(totalFingers), (50, 425), cv2.FONT_HERSHEY_PLAIN,\n",
        "                    10, (255, 0, 0), 25)\n",
        "    cTime = time.time()\n",
        "    fps = 1 / (cTime - pTime)\n",
        "    pTime = cTime\n",
        "    cv2.putText(img, f'FPS: {int(fps)}', (400, 70), cv2.FONT_HERSHEY_PLAIN,\n",
        "                3, (255, 0, 0), 3)\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "IQKxWHPNmMpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Project - 3 - AI personal trainer"
      ],
      "metadata": {
        "id": "E2iahjLLRp0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import PoseModule as pm\n",
        "\n",
        "cap = cv2.VideoCapture(\"AiTrainer/curls.mp4\")\n",
        "detector = pm.poseDetector()\n",
        "\n",
        "count = 0\n",
        "dir = 0\n",
        "pTime = 0\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    img = cv2.resize(img, (1280, 720))\n",
        "    #img = cv2.imread(\"AiTrainer/test.jpg\")\n",
        "    img = detector.findPose(img, False)\n",
        "    lmList = detector.findPosition(img, False)\n",
        "    #print(lmList)\n",
        "    if len(lmList) != 0:\n",
        "        # Right Arm\n",
        "        #angle = detector.findAngle(img, 12, 14, 16)\n",
        "        # # Left Arm\n",
        "        angle = detector.findAngle(img, 11, 13, 15)\n",
        "        per = np.interp(angle, (210, 310), (0, 100))\n",
        "        bar = np.interp(angle, (220, 310), (650, 100))\n",
        "        # print(angle, per)\n",
        "\n",
        "        # Check for the dumbbell curls\n",
        "        color = (255, 0, 255)\n",
        "        if per == 100:\n",
        "            color = (0, 255, 0)\n",
        "            if dir == 0:\n",
        "                count += 0.5\n",
        "                dir = 1\n",
        "        if per == 0:\n",
        "            color = (0, 255, 0)\n",
        "            if dir == 1:\n",
        "                count += 0.5\n",
        "                dir = 0\n",
        "        print(count)\n",
        "\n",
        "        # Draw Bar\n",
        "        cv2.rectangle(img, (1100, 100), (1175, 650), color, 3)\n",
        "        cv2.rectangle(img, (1100, int(bar)), (1175, 650), color, cv2.FILLED)\n",
        "        cv2.putText(img, f'{int(per)} %', (1100, 75), cv2.FONT_HERSHEY_PLAIN, 4,\n",
        "                    color, 4)\n",
        "\n",
        "        # Draw Curl Count\n",
        "        cv2.rectangle(img, (0, 450), (250, 720), (0, 255, 0), cv2.FILLED)\n",
        "        cv2.putText(img, str(int(count)), (45, 670), cv2.FONT_HERSHEY_PLAIN, 15,\n",
        "                    (255, 0, 0), 25)\n",
        "\n",
        "    cTime = time.time()\n",
        "    fps = 1 / (cTime - pTime)\n",
        "    pTime = cTime\n",
        "    cv2.putText(img, str(int(fps)), (50, 100), cv2.FONT_HERSHEY_PLAIN, 5,\n",
        "                (255, 0, 0), 5)\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "hiMbaw5cUXIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chapter - 2 - Lesson -2 -  Pose Estimation - Module (Modified with an additional method \"findPosition\")"
      ],
      "metadata": {
        "id": "4GSclp94oE5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "import math\n",
        "class poseDetector():\n",
        "    def __init__(self, mode=False, model_complexity=1, smooth=True, esegmentation=False,\n",
        "                 ssegmentation=True, detectionCon=0.5, trackCon=0.5):\n",
        "        self.mode = mode\n",
        "        self.model_complexity = model_complexity\n",
        "        self.smooth = smooth\n",
        "        self.esegmentation = esegmentation\n",
        "        self.ssegmentation = ssegmentation\n",
        "        self.detectionCon = detectionCon\n",
        "        self.trackCon = trackCon\n",
        "        self.mpDraw = mp.solutions.drawing_utils\n",
        "        self.mpPose = mp.solutions.pose\n",
        "        self.pose = self.mpPose.Pose(self.mode, self.model_complexity, self.smooth, self.esegmentation,\n",
        "                                     self.ssegmentation, self.detectionCon, self.trackCon)\n",
        "    def findPose(self, img, draw=True):\n",
        "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        self.results = self.pose.process(imgRGB)\n",
        "        if self.results.pose_landmarks:\n",
        "            if draw:\n",
        "                self.mpDraw.draw_landmarks(img, self.results.pose_landmarks,\n",
        "                                           self.mpPose.POSE_CONNECTIONS)\n",
        "        return img\n",
        "\n",
        "    def findPosition(self, img, draw=True):\n",
        "        self.lmList = []\n",
        "        if self.results.pose_landmarks:\n",
        "            for id, lm in enumerate(self.results.pose_landmarks.landmark):\n",
        "                h, w, c = img.shape\n",
        "                # print(id, lm)\n",
        "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "                self.lmList.append([id, cx, cy])\n",
        "                if draw:\n",
        "                    cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
        "        return self.lmList\n",
        "\n",
        "    def findAngle(self, img, p1, p2, p3, draw=True):\n",
        "\n",
        "        # Get the landmarks\n",
        "        x1, y1 = self.lmList[p1][1:]\n",
        "        x2, y2 = self.lmList[p2][1:]\n",
        "        x3, y3 = self.lmList[p3][1:]\n",
        "\n",
        "        # Calculate the Angle\n",
        "        angle = math.degrees(math.atan2(y3 - y2, x3 - x2) -\n",
        "                             math.atan2(y1 - y2, x1 - x2))\n",
        "        if angle < 0:\n",
        "            angle += 360\n",
        "\n",
        "        # print(angle)\n",
        "\n",
        "        # Draw\n",
        "        if draw:\n",
        "            cv2.line(img, (x1, y1), (x2, y2), (255, 255, 255), 3)\n",
        "            cv2.line(img, (x3, y3), (x2, y2), (255, 255, 255), 3)\n",
        "            cv2.circle(img, (x1, y1), 10, (0, 0, 255), cv2.FILLED)\n",
        "            cv2.circle(img, (x1, y1), 15, (0, 0, 255), 2)\n",
        "            cv2.circle(img, (x2, y2), 10, (0, 0, 255), cv2.FILLED)\n",
        "            cv2.circle(img, (x2, y2), 15, (0, 0, 255), 2)\n",
        "            cv2.circle(img, (x3, y3), 10, (0, 0, 255), cv2.FILLED)\n",
        "            cv2.circle(img, (x3, y3), 15, (0, 0, 255), 2)\n",
        "            #cv2.putText(img, str(int(angle)), (x2 - 50, y2 + 50),\n",
        "             #           cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
        "        return angle\n",
        "\n",
        "def main():\n",
        "    cap = cv2.VideoCapture('PoseVideos/3.mp4')\n",
        "    pTime = 0\n",
        "    detector = poseDetector()\n",
        "    while True:\n",
        "        success, img = cap.read()\n",
        "        img = detector.findPose(img)\n",
        "        lmList = detector.findPosition(img, draw=False)\n",
        "        if len(lmList) != 0:\n",
        "            print(lmList[14])\n",
        "            cv2.circle(img, (lmList[14][1], lmList[14][2]), 15, (0, 0, 255), cv2.FILLED)\n",
        "        cTime = time.time()\n",
        "        fps = 1 / (cTime - pTime)\n",
        "        pTime = cTime\n",
        "        cv2.putText(img, str(int(fps)), (70, 50), cv2.FONT_HERSHEY_PLAIN, 3,\n",
        "                    (255, 0, 0), 3)\n",
        "        cv2.imshow(\"Image\", img)\n",
        "        cv2.waitKey(1)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "v1jdyakgoDCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Project - 4 - AI Virtual Painter"
      ],
      "metadata": {
        "id": "3iJ9NhdJoaXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import HandTrackingModule as htm\n",
        "\n",
        "# #######################\n",
        "brushThickness = 25\n",
        "eraserThickness = 100\n",
        "# ########################\n",
        "\n",
        "folderPath = \"Header\"\n",
        "myList = os.listdir(folderPath)\n",
        "myList = sorted(myList)\n",
        "print(myList)\n",
        "\n",
        "overlayList = []\n",
        "for imPath in myList:\n",
        "    image = cv2.imread(f'{folderPath}/{imPath}')\n",
        "    #print('Original Dimensions : ', image.shape)\n",
        "    image = cv2.resize(image, (640,125), interpolation=cv2.INTER_AREA)\n",
        "    #print('resized Dimensions : ', image.shape)\n",
        "    overlayList.append(image)\n",
        "#print(len(overlayList))\n",
        "\n",
        "header = overlayList[0]\n",
        "drawColor = (255, 0, 255)\n",
        "\n",
        "cap = cv2.VideoCapture(-1)\n",
        "cap.set(3, 1280)\n",
        "cap.set(4, 720)\n",
        "\n",
        "detector = htm.handDetector(detectionCon=0.65,maxHands=1)\n",
        "xp, yp = 0, 0\n",
        "imgCanvas = np.zeros((720, 1280, 3), np.uint8)\n",
        "\n",
        "while True:\n",
        "    # 1. Import image\n",
        "    success, img = cap.read()\n",
        "    img = cv2.flip(img, 1)\n",
        "\n",
        "    # 2. Find Hand Landmarks\n",
        "    img = detector.findHands(img)\n",
        "    lmList = detector.findPosition(img, draw=False)\n",
        "\n",
        "    if len(lmList) != 0:\n",
        "        # print(lmList)\n",
        "        # tip of index and middle fingers\n",
        "        x1, y1 = lmList[8][1:]\n",
        "        x2, y2 = lmList[12][1:]\n",
        "\n",
        "        # 3. Check which fingers are up\n",
        "        fingers = detector.fingersUp()\n",
        "        #print(fingers)\n",
        "\n",
        "        # 4. If Selection Mode – Two finger are up\n",
        "        if fingers[1] and fingers[2]:\n",
        "            xp, yp = 0, 0\n",
        "            print(\"Selection Mode\")\n",
        "\n",
        "            # Checking for the click\n",
        "            if y1 < 125:\n",
        "                if 250 < x1 < 450:\n",
        "                    header = overlayList[0]\n",
        "                    drawColor = (255, 0, 255)\n",
        "\n",
        "                elif 550 < x1 < 750:\n",
        "                    header = overlayList[1]\n",
        "                    drawColor = (255, 0, 0)\n",
        "\n",
        "                elif 800 < x1 < 950:\n",
        "                    header = overlayList[2]\n",
        "                    drawColor = (0, 255, 0)\n",
        "\n",
        "                elif 1050 < x1 < 1200:\n",
        "                    header = overlayList[3]\n",
        "                    drawColor = (0, 0, 0)\n",
        "            cv2.rectangle(img, (x1, y1 - 25), (x2, y2 + 25), drawColor, cv2.FILLED)\n",
        "\n",
        "        # 5. If Drawing Mode – Index finger is up\n",
        "        if fingers[1] and fingers[2] == False:\n",
        "            cv2.circle(img, (x1, y1), 15, drawColor, cv2.FILLED)\n",
        "            print(\"Drawing Mode\")\n",
        "        if xp == 0 and yp == 0:\n",
        "            xp, yp = x1, y1\n",
        "\n",
        "        cv2.line(img, (xp, yp), (x1, y1), drawColor, brushThickness)\n",
        "\n",
        "        if drawColor == (0, 0, 0):\n",
        "            cv2.line(img, (xp, yp), (x1, y1), drawColor, eraserThickness)\n",
        "            cv2.line(imgCanvas, (xp, yp), (x1, y1), drawColor, eraserThickness)\n",
        "        else:\n",
        "            cv2.line(img, (xp, yp), (x1, y1), drawColor, brushThickness)\n",
        "            cv2.line(imgCanvas, (xp, yp), (x1, y1), drawColor, brushThickness)\n",
        "\n",
        "        xp, yp = x1, y1\n",
        "\n",
        "    # Clear Canvas when all fingers are up\n",
        "    # if all (x >= 1 for x in fingers):\n",
        "    # imgCanvas = np.zeros((720, 1280, 3), np.uint8)\n",
        "\n",
        "    imgGray = cv2.cvtColor(imgCanvas, cv2.COLOR_BGR2GRAY)\n",
        "    _, imgInv = cv2.threshold(imgGray, 50, 255, cv2.THRESH_BINARY_INV)\n",
        "    imgInv = cv2.cvtColor(imgInv,cv2.COLOR_GRAY2BGR)\n",
        "    img = cv2.bitwise_and(img,imgInv)\n",
        "    img = cv2.bitwise_or(img,imgCanvas)\n",
        "\n",
        "    # Setting the header image\n",
        "    img[0:125, 0:1280] = header\n",
        "    # img = cv2.addWeighted(img,0.5,imgCanvas,0.5,0)\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    cv2.imshow(\"Canvas\", imgCanvas)\n",
        "    # cv2.imshow(\"Inv\", imgInv)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "TCCCKk6porE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chapter 1 - lesson 2 - Hand Tracking Module (modified by adding a method \"fingersUp\")"
      ],
      "metadata": {
        "id": "-W5QEQl_Eg5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "\n",
        "\n",
        "class handDetector():\n",
        "    def __init__(self, mode=False, maxHands = 2, model_complexity=1, detectionCon = 0.5, trackCon=0.5):\n",
        "        self.mode = mode\n",
        "        self.maxHands = maxHands\n",
        "        self.model_complexity = model_complexity\n",
        "        self.detectionCon = detectionCon\n",
        "        self.trackCon = trackCon\n",
        "\n",
        "        self.mpHands = mp.solutions.hands\n",
        "        self.hands = self.mpHands.Hands(self.mode, self.maxHands, self.model_complexity,\n",
        "                                        self.detectionCon, self.trackCon)\n",
        "        self.mpDraw = mp.solutions.drawing_utils\n",
        "        self.tipIds = [4, 8, 12, 16, 20]\n",
        "\n",
        "\n",
        "    def findHands(self, img, draw=True):\n",
        "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        self.results = self.hands.process(imgRGB)\n",
        "        # print(results.multi_hand_landmarks)\n",
        "\n",
        "        if self.results.multi_hand_landmarks:\n",
        "            for handLms in self.results.multi_hand_landmarks:\n",
        "                if draw:\n",
        "                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def findPosition(self, img, handNo=0, draw=True):\n",
        "\n",
        "        self.lmList = []\n",
        "        if self.results.multi_hand_landmarks:\n",
        "            myHand = self.results.multi_hand_landmarks[handNo]\n",
        "            for id, lm in enumerate(myHand.landmark):\n",
        "                h, w, c = img.shape\n",
        "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "                #print(id, cx, cy)\n",
        "                self.lmList.append([id, cx, cy])\n",
        "                #print(lmlist)\n",
        "                if draw:\n",
        "                    cv2.circle(img, (cx, cy), 15, (255, 0, 255), cv2.FILLED)\n",
        "\n",
        "        return self.lmList\n",
        "\n",
        "    def fingersUp(self):\n",
        "        fingers = []\n",
        "\n",
        "        # Thumb\n",
        "        if self.lmList[self.tipIds[0]][1] < self.lmList[self.tipIds[0] - 1][1]:\n",
        "            fingers.append(1)\n",
        "        else:\n",
        "            fingers.append(0)\n",
        "\n",
        "        # Fingers\n",
        "        for id in range(1, 5):\n",
        "            if self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id] - 2][2]:\n",
        "                fingers.append(1)\n",
        "            else:\n",
        "                fingers.append(0)\n",
        "\n",
        "            # totalFingers = fingers.count(1)\n",
        "\n",
        "        return fingers\n",
        "\n",
        "\n",
        "def main():\n",
        "    pTime = 0\n",
        "    cTime = 0\n",
        "    cap = cv2.VideoCapture(-1)\n",
        "    detector = handDetector()\n",
        "    while True:\n",
        "        success, img = cap.read()\n",
        "        img = detector.findHands(img, draw = False)\n",
        "        lmlist = detector.findPosition(img, draw=False)\n",
        "        if len(lmlist) != 0:\n",
        "            print(lmlist[4])\n",
        "\n",
        "        cTime = time.time()\n",
        "        fps = 1 / (cTime - pTime)\n",
        "        pTime = cTime\n",
        "\n",
        "        cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)\n",
        "\n",
        "        cv2.imshow(\"Image\", img)\n",
        "        cv2.waitKey(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "9a5h1QXkEmCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Project - 5 - AI Virtual Mouse"
      ],
      "metadata": {
        "id": "ltpeZjSCE8ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import HandTrackingModule as htm\n",
        "import time\n",
        "import autopy\n",
        "\n",
        "##########################\n",
        "wCam, hCam = 640, 480\n",
        "frameR = 100 # Frame Reduction\n",
        "smoothening = 7\n",
        "#########################\n",
        "\n",
        "pTime = 0\n",
        "plocX, plocY = 0, 0\n",
        "clocX, clocY = 0, 0\n",
        "\n",
        "cap = cv2.VideoCapture(-1)\n",
        "cap.set(3, wCam)\n",
        "cap.set(4, hCam)\n",
        "\n",
        "detector = htm.handDetector(maxHands=1)\n",
        "wScr, hScr = autopy.screen.size()\n",
        "print(wScr, hScr)\n",
        "\n",
        "while True:\n",
        "    # 1. Find hand Landmarks\n",
        "    success, img = cap.read()\n",
        "    img = detector.findHands(img)\n",
        "    lmList, bbox = detector.findPosition(img)\n",
        "\n",
        "    # 2. Get the tip of the index and middle fingers\n",
        "    if len(lmList) != 0:\n",
        "        x1, y1 = lmList[8][1:]\n",
        "        x2, y2 = lmList[12][1:]\n",
        "        # print(x1, y1, x2, y2)\n",
        "\n",
        "        # 3. Check which fingers are up\n",
        "        fingers = detector.fingersUp()\n",
        "        # print(fingers)\n",
        "        cv2.rectangle(img, (frameR, frameR), (wCam - frameR, hCam - frameR),\n",
        "                      (255, 0, 255), 2)\n",
        "        # 4. Only Index Finger : Moving Mode\n",
        "        if fingers[1] == 1 and fingers[2] == 0:\n",
        "\n",
        "            # 5. Convert Coordinates\n",
        "            x3 = np.interp(x1, (frameR, wCam - frameR), (0, wScr))\n",
        "            y3 = np.interp(y1, (frameR, hCam - frameR), (0, hScr))\n",
        "\n",
        "            # 6. Smoothen Values\n",
        "            clocX = plocX + (x3 - plocX) / smoothening\n",
        "            clocY = plocY + (y3 - plocY) / smoothening\n",
        "\n",
        "            # 7. Move Mouse\n",
        "            autopy.mouse.move(wScr - clocX, clocY)\n",
        "            cv2.circle(img, (x1, y1), 15, (255, 0, 255), cv2.FILLED)\n",
        "            plocX, plocY = clocX, clocY\n",
        "\n",
        "        # 8. Both Index and middle fingers are up : Clicking Mode\n",
        "        if fingers[1] == 1 and fingers[2] == 1:\n",
        "            # 9. Find distance between fingers\n",
        "            length, img, lineInfo = detector.findDistance(8, 12, img)\n",
        "            # print(length)\n",
        "            # 10. Click mouse if distance short\n",
        "            if length < 40:\n",
        "                cv2.circle(img, (lineInfo[4], lineInfo[5]),\n",
        "                           15, (0, 255, 0), cv2.FILLED)\n",
        "                autopy.mouse.click()\n",
        "\n",
        "    # 11. Frame Rate\n",
        "    cTime = time.time()\n",
        "    fps = 1 / (cTime - pTime)\n",
        "    pTime = cTime\n",
        "    cv2.putText(img, str(int(fps)), (20, 50), cv2.FONT_HERSHEY_PLAIN,\n",
        "                3, (255, 0, 0), 3)\n",
        "\n",
        "    # 12. Display\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "fbWwHB3aFNqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chapter 1 - lesson 2 - Hand Tracking Module (modified quite a lot and a method \"find distance\" is added)"
      ],
      "metadata": {
        "id": "LUIhNE3CeY2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class handDetector():\n",
        "    def __init__(self, mode=False, maxHands = 2, model_complexity=1, detectionCon = 0.5, trackCon=0.5):\n",
        "        self.mode = mode\n",
        "        self.maxHands = maxHands\n",
        "        self.model_complexity = model_complexity\n",
        "        self.detectionCon = detectionCon\n",
        "        self.trackCon = trackCon\n",
        "\n",
        "        self.mpHands = mp.solutions.hands\n",
        "        self.hands = self.mpHands.Hands(self.mode, self.maxHands, self.model_complexity,\n",
        "                                        self.detectionCon, self.trackCon)\n",
        "        self.mpDraw = mp.solutions.drawing_utils\n",
        "        self.tipIds = [4, 8, 12, 16, 20]\n",
        "\n",
        "\n",
        "    def findHands(self, img, draw=True):\n",
        "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        self.results = self.hands.process(imgRGB)\n",
        "        # print(results.multi_hand_landmarks)\n",
        "\n",
        "        if self.results.multi_hand_landmarks:\n",
        "            for handLms in self.results.multi_hand_landmarks:\n",
        "                if draw:\n",
        "                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def findPosition(self, img, handNo=0, draw=True):\n",
        "        xList = []\n",
        "        yList = []\n",
        "        bbox = []\n",
        "        self.lmList = []\n",
        "        if self.results.multi_hand_landmarks:\n",
        "            myHand = self.results.multi_hand_landmarks[handNo]\n",
        "            for id, lm in enumerate(myHand.landmark):\n",
        "                #print(id, lm)\n",
        "                h, w, c = img.shape\n",
        "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "                xList.append(cx)\n",
        "                yList.append(cy)\n",
        "                #print(id, cx, cy)\n",
        "                self.lmList.append([id, cx, cy])\n",
        "                if draw:\n",
        "                    cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)\n",
        "\n",
        "            xmin, xmax = min(xList), max(xList)\n",
        "            ymin, ymax = min(yList), max(yList)\n",
        "            bbox = xmin, ymin, xmax, ymax\n",
        "\n",
        "            if draw:\n",
        "                cv2.rectangle(img, (xmin - 20, ymin - 20), (xmax + 20, ymax + 20),(0, 255, 0), 2)\n",
        "\n",
        "        return self.lmList, bbox\n",
        "\n",
        "    def fingersUp(self):\n",
        "        fingers = []\n",
        "\n",
        "        # Thumb\n",
        "        if self.lmList[self.tipIds[0]][1] > self.lmList[self.tipIds[0] - 1][1]:\n",
        "            fingers.append(1)\n",
        "        else:\n",
        "            fingers.append(0)\n",
        "\n",
        "        # Fingers\n",
        "        for id in range(1, 5):\n",
        "            if self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id] - 2][2]:\n",
        "                fingers.append(1)\n",
        "            else:\n",
        "                fingers.append(0)\n",
        "\n",
        "            # totalFingers = fingers.count(1)\n",
        "\n",
        "        return fingers\n",
        "\n",
        "    def findDistance(self, p1, p2, img, draw=True, r=15, t=3):\n",
        "        x1, y1 = self.lmList[p1][1:]\n",
        "        x2, y2 = self.lmList[p2][1:]\n",
        "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "\n",
        "        if draw:\n",
        "            cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), t)\n",
        "            cv2.circle(img, (x1, y1), r, (255, 0, 255), cv2.FILLED)\n",
        "            cv2.circle(img, (x2, y2), r, (255, 0, 255), cv2.FILLED)\n",
        "            cv2.circle(img, (cx, cy), r, (0, 0, 255), cv2.FILLED)\n",
        "        length = math.hypot(x2 - x1, y2 - y1)\n",
        "\n",
        "        return length, img, [x1, y1, x2, y2, cx, cy]\n",
        "\n",
        "\n",
        "def main():\n",
        "    pTime = 0\n",
        "    cTime = 0\n",
        "    cap = cv2.VideoCapture(-1)\n",
        "    detector = handDetector()\n",
        "    while True:\n",
        "        success, img = cap.read()\n",
        "        img = detector.findHands(img)\n",
        "        lmList, bbox = detector.findPosition(img)\n",
        "        if len(lmList) != 0:\n",
        "            print(lmList[4])\n",
        "\n",
        "        cTime = time.time()\n",
        "        fps = 1 / (cTime - pTime)\n",
        "        pTime = cTime\n",
        "\n",
        "        cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)\n",
        "\n",
        "        cv2.imshow(\"Image\", img)\n",
        "        cv2.waitKey(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "hRE-91Rqenue"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}